---
title: "Exercício 7 - Análise de Dados"
author: "Felipe Lira Paiva"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Carregando os pacotes, abrindo o banco...

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(knitr)
library(haven)
library(readr)
library(readxl)
library(vcd)
library(scales)
library(graphics)
library(dotwhisker)
library(lmtest)
library(car)
library(MASS)


Baseatividade6 <- read_sav("C:/Users/Felipe/Desktop/Baseatividade6.sav")

View(Baseatividade6)

```


### Questão 1

No exercício anterior foram feitos alguns modelos bivariados. Agora faça uma regressão multivariada mostrando como a nota atribuída a Jair Bolsonaro (variável `Q1607`) pode ser explicada pelas variáveis idade (`D1A_ID`), educação (`D3_ESCOLA`), renda (`D9`), nota atribuída ao PT (`Q1501`) e auto-atribuição ideológica (`Q18`) dos respondentes. Interprete o resultado a partir das informações dadas pelo sumário da regressão.

```{r, warning = FALSE}
atv7 <- Baseatividade6

atv7$Q1607 <- as.numeric(atv7$Q1607)

questao1 <- atv7 %>%
        filter(Q1607 <= 10,
               D9 < 9999998,
               Q1501 <= 10,
               Q18 <= 10)

reg1 <- lm(Q1607 ~ D1A_ID + D3_ESCOLA + D9 + Q1501 + Q18, data = questao1)
           
           
      summary(reg1)
      confint(reg1)

```

Resposta: 

No modelo de regressão, observamos que as variáveis idade (`D1A_ID`) e renda (`D9`) não são estatisticamente significativas, pelo p-valor ser muito alto; as demais variáveis possuem um p-valor baixo. Quando a escolaridade aumenta em uma unidade, a nota atribuída a Bolsonaro diminui em 0,1543. Quando uma unidade é aumentada na nota do PT, a nota de Bolsonaro é 0.415 menor. Quando a auto-atribuição ideológica é aumentada em uma unidade, a nota de Bolsonaro é aumentada em 0.3244. O valor do intercepto é 5,743. O R-quadrado é 0,28, o que significa que o nosso modelo explica 28% da realidade. O R-quadrado ajustado, que "pune" variáveis ruins, é de 0,28 (a diferença está nas outras casas decimais). O nosso modelo erra, em média, 3,336 pontos. Também vimos os coeficientes a partir do "confint": podemos notar que as duas variáveis de alto p-valor passam pelo zero, enquanto as demais não passam. 

### Questão 2

Em que medida os resultados se mantém ou se alteram quando comparados com os resultados do exercício anterior, quando foram utilizadas apenas regressões bivariadas?

Resposta:

No exercício passado, deram significativos: Idade (coeficiente de 0,025), escolaridade (coeficiente de -0.118), nota atribuída ao PT (-0.411) e auto-avaliação ideológica (0.409). Enquanto, a renda não deu significativo. Portanto, de primeira, vemos que perdemos a significância da idade em relação ao modelo anterior. Ademais, todas as relações continuaram na mesma direção (o que era positivo, continuou positivo e vice-versa). O R-quadrado também merece destaque, pois o modelo deste exercício explica muito mais a realidade do que os modelos bivariados da atividade anterior. O erro padrão é menor neste modelo em relação aos modelos bivariados. Quanto aos valores dos coeficientes, a escolaridade, antes, era -0,118 e, agora, é -0,1543 (pequena mudança), a nota atribuída ao PT tinha coeficiente -0,411 e, agora, tem -0,4154 (ou seja, quase nenhuma mudança) e a auto-avaliação ideológica era 0.409 e foi para 0,3244 (maior mudança entre os coeficientes).

### Questão 3

A partir da exposição de gráficos e testes, avalie se o modelo se adequa aos pressupostos que uma regressão linear exige. 

```{r, warning = FALSE}
plot(reg1, 1)

plot(reg1, 3)
bptest(reg1)
ncvTest(reg1) 

acf(reg1$residuals)
durbinWatsonTest(reg1)

plot(reg1, 2)
sresid <- studres(reg1) 
shapiro.test(sresid)

```

Linearidade: idealmente, a linha vermelha deve ser horizontal à linha pontilhada (que está bem no meio do gráfico), entretanto, observamos algumas oscilações pequenas, especialmente nas pontas.

Homocedasticidade: Aqui, o importante é que os pontos estejam distribuídos para cima, para baixo e ao longo do eixo x. Fizemos também os dois testes; se nossa hipótese nula é que há homocedasticidade, o resultado desejado é um p-valor alto, porém, observamos nos testes p-valor extremamente baixos, indicando que o pressuposto da homocedasticidade não está satisfeito.

Autocorrelação entre casos/resíduos: o resultado ideal é que todas as linahs (com exceção da primeira) estejam dentro do tracejado azul. A hipótese nula é que não existe correlação (portanto, esperamos um p-valor alto). O p-valor do teste foi de 0.034, satisfazendo o pressuposto.

Normalidade dos resíduos: aqui, o ideal é que os pontos estejam próximos da linha diagonal, porém observamos que isso não acontece no "meio" e nas pontas. A partir do teste de normalidade, também esperávamos que o p-valor fosse alto para não rejeitar a hipótese nula, mas observamos que ele é baixo, de forma que esse pressuposto não está sendo satisfeito.

### Questão 4

Caso algum pressuposto não seja satisfeito, quais são as consequências específicas para o modelo estimado?

Que podemos colocar em xeque o resultado da regressão linear, mas sabendo que há formas de trabalhar os dados (seja com outras regressões, seja com técnicas para lidar com esses dados). A falta de linearidade pode indicar que a relação das variáveis não é linear (ou seja, seria necessária outra regressão). A falta homocedasticidade indica que os erros não tem variância comum. E a falta de normalidade dos resíduos indica que eles não possuem uma distribuição normal.

### Questão 5

Considerando o 4o hurdle do livro *Fundamentals...*, faça um modelo de regressão extra adicionando uma variável **numérica** que foi omitida do modelo anterior, mas que possa ter relação causal com a variável dependente (e talvez alguma associação com as independentes anteriores). Justifique a variável extra e analise o resultado. 

```{r, warning = FALSE}
questao2 <- atv7 %>%
        filter(Q1607 <= 10,
               D9 < 9999998,
               Q1501 <= 10,
               Q18 <= 10,
               Q1505 <= 10)

reg2 <- lm(Q1607 ~ D1A_ID + D3_ESCOLA + D9 + Q1501 + Q18 + Q1505, data = questao2)
           
           
      summary(reg2)
      confint(reg2)

```

Resposta:

A variável adicionada foi a avaliação ao PSDB. Bolsonaro foi eleito com um discurso contra o petismo e, durante muitos anos, o partido que protagonizou a cena política com o PT foi o PSDB. Porém, desde 2002, o PSDB não obteve sucesso em derrotar o PT nas urnas (4 eleições consecutivas). Assim, seria de se esperar que parte do eleitorado do PSDB, movido pelo antipetismo, se aproximaria de Bolsonaro, candidato com mais chances de derrotar o PT. O que se espera da regressão é, portanto, uma relação positiva entre as variáveis.

Com o resultado da regressão, observamos que a nossa hipótese é corroborada, ainda que o impacto seja pequeno. O p-valor é baixo e o coeficiente é 0,2669 (ou seja, o aumento de uma unidade na nota atribuída ao PSDB, aumenta em 0,2669 a avaliação a Bolsonaro). É interessante notar que a significância estatística da escolaridade diminuiu um pouco (mas o p-valor ainda é baixo), o erro padrão do modelo também diminuiu um pouco, o R-quadrado aumentou em cerca de 5%, e o intercepto diminuiu, ficando em 4,7.


### Questão 6

Compare o resultado obtido com o modelo e conclusões anteriores.

Resposta:

Uma das primeiras coisas que nos chama a atenção é a diminuição da significância estatistica da escolaridade (mas o p-valor ainda é baixo e significante a 0.001). A adição de apenas essa nova variável também ajudou a melhorar o R-quadrado e o R-quadrado ajustado, que possuem, respectivamente 33,96% e 33,65%. O valor do intercepto também merece ser notado, pois diminuiu: antes era de 5.743 e agora está em 4.708. O erro padrão também diminuiu, mas  foi pouco: de 3.336 para 3196. É importante notar que nossa amostra diminuiu um pouco, em aproximadamente 200 casos, pois foram excluídos os casos que os respondentes não avaliaram o PSDB.